# Stage 2: full actions. Fixed-load + nearest-K candidates.
# Load weights from stage1 (see commands below).
# Suggested usage:
#   python scripts/train.py --config configs/phase1_actions_queuefix_v3_3_stage2_full.yaml --updates 60 --log_dir runs/phase1_actions --run_id stage2_full --init_actor runs/phase1_actions/stage1_accel/actor.pt --init_critic runs/phase1_actions/stage1_accel/critic.pt
seed: 42
map_size: 3000.0
tau0: 1.0
T_steps: 100

num_uav: 3
num_gu: 20
num_sat: 72
walker_num_planes: 6
sat_state_max: 9

users_obs_max: 20
sats_obs_max: 6
visible_sats_max: 6
visible_sats_min: null
nbrs_obs_max: 4

uav_height: 100.0
sat_height: 500000.0
theta_min_deg: 5.0
v_max: 30.0
a_max: 5.0
d_safe: 20.0
boundary_mode: reflect

# Candidate users: nearest-K (K=20)
candidate_mode: "nearest"
candidate_k: 20

# Curriculum spawn: start near GU, expand radius, then full random.
uav_spawn_curriculum_enabled: true
uav_spawn_radius_start: 100.0
uav_spawn_radius_end: 1000.0
uav_spawn_curriculum_steps: 200
uav_spawn_full_random_final: true

# Arrivals (fixed load, no ramp)
task_arrival_rate: 7.0e4
task_arrival_poisson: true
arrival_ramp_steps: 0
arrival_ramp_start: 0.0
arrival_ramp_use_global: false
queue_init_frac: 0.1

gu_tx_power: 0.18
uav_tx_gain: 300.0
sat_rx_gain: 300.0
b_acc: 1.0e7
b_sat_total: 2.0e7
sat_cpu_freq: 1.0e10
noise_density: 4.0e-21
pathloss_mode: prob_los
pl_threshold_db: 140.0

doppler_observed: true
doppler_enabled: false
energy_enabled: false
fading_enabled: false
interference_enabled: false

# Stage 2: full actions
enable_bw_action: true
fixed_satellite_strategy: false
sat_select_mode: sample
N_RF: 2

avoidance_enabled: true
avoidance_eta: 100.0
avoidance_alert_factor: 1.5
eta_crash: 5.0

# Reward (start from best fixedload_nearest_k20)
omega_q: 1.1
omega_q_gu: 1.0
omega_q_uav: 0.0
omega_q_sat: 0.0
eta_drop: 1.3
eta_service: 1.3
eta_assoc: 0.1
eta_q_delta: 1.0
eta_accel: 0.02
eta_centroid: 0.8
centroid_dist_scale: 400.0
eta_bw_align: 0.4
eta_sat_score: 0.05
eta_dist_delta: 0.4
queue_log_k: 6.0
queue_delta_use_active: true

input_norm_enabled: true
reward_norm_enabled: true
reward_norm_clip: 5.0
reward_tanh_enabled: false
critic_lr: 1.0e-4

# Imitation loss (queue_aware): full actions
imitation_enabled: true
imitation_coef: 0.4
imitation_accel: true
imitation_bw: true
imitation_sat: false

# Faster PPO
buffer_size: 400
num_mini_batch: 4
ppo_epochs: 1
entropy_coef: 0.005

early_stop_enabled: false
